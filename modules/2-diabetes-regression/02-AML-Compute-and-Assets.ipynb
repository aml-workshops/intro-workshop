{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "precious-youth",
   "metadata": {},
   "source": [
    "# Working with AML Compute and other AML Assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wooden-fiber",
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace, Environment, Dataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pacific-animation",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_NAME = 'ENTER_YOUR_NAME_HERE'\n",
    "\n",
    "ENVIRONMENT_NAME = f'sklearn-{USER_NAME}'\n",
    "DATASET_NAME = f'diabetes-{USER_NAME}'\n",
    "\n",
    "DATA_PATH = \"./data\"\n",
    "BLOB_PATH = f'/data/{USER_NAME}'\n",
    "\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflected-married",
   "metadata": {},
   "source": [
    "## AML Compute Assets\n",
    "\n",
    "![Compute Assets](../../media/7-compute-assets.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "willing-geneva",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's print out the details for each of our available compute targets\n",
    "pd.DataFrame.from_records(\n",
    "    [\n",
    "        {'Compute Name': name, \n",
    "         'Compute Type': ct.type}\n",
    "         for name, ct \n",
    "        in ws.compute_targets.items()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaningful-northwest",
   "metadata": {},
   "source": [
    "---\n",
    "## AML Environments\n",
    "\n",
    "With AML, you can define and register \"Environments\" - that can be used across AML. The environment can specify everything from the Docker base image used, to environment variables to set, and the Python packages to install. \n",
    "\n",
    "Let's define and register a new environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expected-basket",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_env = Environment(ENVIRONMENT_NAME)\n",
    "sklearn_env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brave-graphics",
   "metadata": {},
   "source": [
    "### Adding more Python Packages\n",
    "By default (at the time this notebook was written), our new environment is based on Python 3.6.2 and only has 1 pip package included. Let's update the python version and add a few more required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unauthorized-brooks",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update Python Version\n",
    "sklearn_env.python.conda_dependencies.set_python_version(\"3.9.2\")\n",
    "\n",
    "# Add conda packages\n",
    "sklearn_env.python.conda_dependencies.add_conda_package(\"pip\")\n",
    "sklearn_env.python.conda_dependencies.add_conda_package(\"scikit-learn=0.24.1\")\n",
    "sklearn_env.python.conda_dependencies.add_conda_package(\"seaborn=0.11.1\")\n",
    "sklearn_env.python.conda_dependencies.add_conda_package(\"click=7.1.2\")\n",
    "sklearn_env.python.conda_dependencies.add_conda_package(\"joblib=1.0.1\")\n",
    "\n",
    "# Enable Docker for the environment\n",
    "sklearn_env.docker.enabled = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integrated-houston",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civic-genome",
   "metadata": {},
   "source": [
    "### Environment Registration\n",
    "Next - let's \"register\" this environment to the AML Workspace. That will allow us leverage the environment during multiple use cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inner-specification",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_env = sklearn_env.register(ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approved-estonia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional - build the underlying Docker container\n",
    "build = sklearn_env.build(ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inclusive-brisbane",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# If azureml.widgets we can look into the build progress.\n",
    "build.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "robust-margin",
   "metadata": {},
   "source": [
    "---\n",
    "## Datastores and Datasets\n",
    "\n",
    "Next, we will examine Datastores and Datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amateur-pilot",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Datastores:\")\n",
    "for k in ws.datastores.keys():\n",
    "    print(f\"- {k}\")\n",
    "print()\n",
    "\n",
    "print(\"Datasets:\")\n",
    "for k in ws.datasets.keys():\n",
    "    print(f\"- {k}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "included-tracy",
   "metadata": {},
   "source": [
    "### Creating Diabetes Dataset\n",
    "Next, let's create a new dataset for our diabetes data using the CSV file in the data folder. We can do this a few ways. \n",
    "\n",
    "First, it's possible in the UI.\n",
    "<br>![Dataset Creation](../../media/8-dataset-creation-ui.gif)\n",
    "\n",
    "Below, we'll be uploading and using programatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acquired-prerequisite",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we'll upload the diabetes CSV to our workspaceblobstore\n",
    "datastore = ws.datastores['workspaceblobstore']\n",
    "\n",
    "uploaded_file = datastore.upload_files(\n",
    "    files=[f'{DATA_PATH}/diabetes.csv'], \n",
    "    relative_root=DATA_PATH, \n",
    "    target_path=BLOB_PATH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunrise-pasta",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we'll register this dataset.\n",
    "dataset = Dataset.File.from_files((datastore, f'{BLOB_PATH}/diabetes.csv'))\n",
    "\n",
    "dataset = dataset.register(\n",
    "    workspace=ws, \n",
    "    name=DATASET_NAME, \n",
    "    description=f\"The diabetes CSV file for {USER_NAME}\",\n",
    "    create_new_version=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advance-finding",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Datastores:\")\n",
    "for k in ws.datastores.keys():\n",
    "    print(f\"- {k}\")\n",
    "print()\n",
    "\n",
    "print(\"Datasets:\")\n",
    "for k in ws.datasets.keys():\n",
    "    print(f\"- {k}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "talented-launch",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###### Copyright (c) Microsoft Corporation. All rights reserved.  \n",
    "###### Licensed under the MIT License."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
